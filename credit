{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1668812876915,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "8o92tL1ruqih"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21250,
     "status": "ok",
     "timestamp": 1668812898120,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "_UWzJ9fH4oXJ",
    "outputId": "687dcd2b-3448-48b9-ffb4-aec3e1a4caea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 7162,
     "status": "ok",
     "timestamp": 1668812905274,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "v4jWvnTIwZkK",
    "outputId": "5d77a91b-0e16-4284-f040-ba913ee2f8fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-49c737c5-08d3-4153-9a72-476401e40b02\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.619995</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.660004</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798279</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.989998</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49c737c5-08d3-4153-9a72-476401e40b02')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-49c737c5-08d3-4153-9a72-476401e40b02 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-49c737c5-08d3-4153-9a72-476401e40b02');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798279 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28      Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.619995    0.0  \n",
       "1  0.125895 -0.008983  0.014724    2.690000    0.0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.660004    0.0  \n",
       "3 -0.221929  0.062723  0.061458  123.500000    0.0  \n",
       "4  0.502292  0.219422  0.215153   69.989998    0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creditcart.csv 경로에서 ... -> 경로복사 후 ctrl + V \n",
    "df = pd.read_csv('/content/drive/MyDrive/creditcard.csv', dtype = np.float32)\n",
    "#df = pd.read_csv('creditcard.csv', dtype = np.float32)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jygkpEKzxcKQ"
   },
   "source": [
    "##  tensorflow logistic regression vs sklearn LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1668813642799,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "EGkBkFOEzV9c"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BkBX7wh3fbP"
   },
   "source": [
    "# 데이터 전처리 및 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "executionInfo": {
     "elapsed": 1286,
     "status": "ok",
     "timestamp": 1668813644073,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "S7eeJxg93j_f",
    "outputId": "3d56da08-1a99-4f41-cabd-94b9707bad05"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-33706f9e-3ca6-45f5-8c3a-1dda5becbf6a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.867188</td>\n",
       "      <td>1.339397e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.800400e-08</td>\n",
       "      <td>6.643411e-09</td>\n",
       "      <td>2.657364e-08</td>\n",
       "      <td>-1.500125e-09</td>\n",
       "      <td>-1.071518e-09</td>\n",
       "      <td>-1.071518e-10</td>\n",
       "      <td>-3.214554e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.928732e-09</td>\n",
       "      <td>3.643161e-09</td>\n",
       "      <td>3.214554e-10</td>\n",
       "      <td>1.259033e-09</td>\n",
       "      <td>2.143036e-09</td>\n",
       "      <td>1.034684e-09</td>\n",
       "      <td>1.138488e-10</td>\n",
       "      <td>-1.272427e-10</td>\n",
       "      <td>88.349609</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.144531</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120117</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-72.715729</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-0.598550</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>0.065486</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097605e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>0.803724</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273458e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165001</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>22.057730</td>\n",
       "      <td>9.382559e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519588e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160156</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33706f9e-3ca6-45f5-8c3a-1dda5becbf6a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-33706f9e-3ca6-45f5-8c3a-1dda5becbf6a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-33706f9e-3ca6-45f5-8c3a-1dda5becbf6a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                Time            V1             V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  284807.000000  2.848070e+05  2.848070e+05   \n",
       "mean    94813.867188  1.339397e-08       0.000000 -4.800400e-08  6.643411e-09   \n",
       "std     47488.144531  1.958696e+00       1.651309  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01     -72.715729 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01      -0.598550 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02       0.065486  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00       0.803724  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00      22.057730  9.382559e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   2.657364e-08 -1.500125e-09 -1.071518e-09 -1.071518e-10 -3.214554e-10   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273458e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ... -1.928732e-09  3.643161e-09  3.214554e-10  1.259033e-09   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097605e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   2.143036e-09  1.034684e-09  1.138488e-10 -1.272427e-10      88.349609   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120117   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165001   \n",
       "max    7.519588e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160156   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1668813644082,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "MLiRBsoZ3ppV",
    "outputId": "77576999-bc56-4ac8-feb0-1ded2da5a066"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치가 있는 열 확인. 0보다 큰 값이 있으면 NaN이 있는 행이 count된 것임\n",
    "# 결측치 없음으로 확인됨\n",
    "df.isna().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1668813644083,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "I3m8wI2GWTo0",
    "outputId": "bba5e2f2-6f11-4e30-9487-bd347792524d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-febaae28-8d0a-4877-b9cc-b7f686de0288\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>284315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-febaae28-8d0a-4877-b9cc-b7f686de0288')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-febaae28-8d0a-4877-b9cc-b7f686de0288 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-febaae28-8d0a-4877-b9cc-b7f686de0288');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         Time\n",
       "Class        \n",
       "0.0    284315\n",
       "1.0       492"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class별 개수 count\n",
    "df.groupby(['Class'])[['Time']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71PMbFKLWpHg"
   },
   "source": [
    "* imbalance data $\\Rightarrow$ oversampling / undersampling 또는 학습시 가중치 설정 고려 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1668813644389,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "zRwxaF3T2jlU"
   },
   "outputs": [],
   "source": [
    "# X와 y 설정\n",
    "# X : Time열 제외\n",
    "# y : target. 'Class'열\n",
    "X = df.iloc[:, 1:-1]\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1668813644390,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "lYVcDnmWyo_8",
    "outputId": "13f4ae82-758c-43cd-b555-862be34accb8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-114acfb2-3358-406a-8d69-642d00c4c6a4\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.619995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.660004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798279</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.989998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-114acfb2-3358-406a-8d69-642d00c4c6a4')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-114acfb2-3358-406a-8d69-642d00c4c6a4 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-114acfb2-3358-406a-8d69-642d00c4c6a4');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V20       V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.524980  0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.408542 -0.009431  0.798279 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28      Amount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.619995  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.690000  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.660004  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.500000  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153   69.989998  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1668813644393,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "2xeJO0FR477-",
    "outputId": "5705268f-4675-4ad7-c9d1-c36de28f1bb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of a training set : 213605\n",
      "Size of a test set : 71202\n",
      "Size of the entire data set 284807\n"
     ]
    }
   ],
   "source": [
    "# dividing X, y into training, test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 40)\n",
    "print('Size of a training set : {}'.format(X_train.shape[0]))\n",
    "print('Size of a test set : {}'.format(X_test.shape[0]))\n",
    "print('Size of the entire data set {}'.format(X.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIGPcMwKBsci"
   },
   "source": [
    "## Logistic regression\n",
    "\n",
    "* tensorflow 이용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2579,
     "status": "ok",
     "timestamp": 1668813647834,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "5uz5m0XjYSb4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1668813647836,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "RGjDWV7NYiRb",
    "outputId": "d8e37d8d-3d87-4fd7-cde2-ed9000c1da4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 29)\n",
      "[[9.3519241e-01 7.6649040e-01 8.8136494e-01 ... 4.1897613e-01\n",
      "  3.1269664e-01 5.8237929e-03]\n",
      " [9.7854203e-01 7.7006662e-01 8.4029853e-01 ... 4.1634512e-01\n",
      "  3.1342265e-01 1.0470528e-04]\n",
      " [9.3521708e-01 7.5311762e-01 8.6814088e-01 ... 4.1548926e-01\n",
      "  3.1191131e-01 1.4738923e-02]\n",
      " ...\n",
      " [9.9090487e-01 7.6407969e-01 7.8110206e-01 ... 4.1659316e-01\n",
      "  3.1258485e-01 2.6421540e-03]\n",
      " [9.5420909e-01 7.7285570e-01 8.4958714e-01 ... 4.1851953e-01\n",
      "  3.1524515e-01 3.8923896e-04]\n",
      " [9.4923186e-01 7.6525640e-01 8.4960151e-01 ... 4.1646636e-01\n",
      "  3.1340083e-01 8.4464857e-03]]\n"
     ]
    }
   ],
   "source": [
    "# scaler : MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_tf = scaler.fit_transform(X)\n",
    "print(X_tf.shape)\n",
    "print(X_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1668813647838,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "5slpBumzfAFx",
    "outputId": "6a09f842-1aad-40c3-d4a0-3a92d814dee4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 1)\n",
      "0         0.0\n",
      "1         0.0\n",
      "2         0.0\n",
      "3         0.0\n",
      "4         0.0\n",
      "         ... \n",
      "284802    0.0\n",
      "284803    0.0\n",
      "284804    0.0\n",
      "284805    0.0\n",
      "284806    0.0\n",
      "Name: Class, Length: 284807, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# 여기서 reshape 해주지 않으면 아래 cost_function 식에서 연산 오류가 발생함\n",
    "y_tf = np.array(y.values, dtype = np.float32).reshape((-1,1))\n",
    "print(y_tf.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1668813648749,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "vSk3EbSVYziM"
   },
   "outputs": [],
   "source": [
    "# W, b\n",
    "W = tf.Variable(tf.random.normal([29,1], dtype = tf.float32)) # W : input dim(X의 컬럼수) * output dim(y의 output수. 이진분류의 경우 1)\n",
    "b = tf.Variable(tf.ones([1], dtype = tf.float32)) # b : bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1668813649744,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "FxRBmIgIZnZ5",
    "outputId": "05b247b3-082a-499d-9201-0ad267c31644"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97685146]\n",
      " [0.9772225 ]\n",
      " [0.966127  ]\n",
      " ...\n",
      " [0.98155206]\n",
      " [0.9845887 ]\n",
      " [0.97129816]]\n"
     ]
    }
   ],
   "source": [
    "def hypothesis(x):\n",
    "  # sigmoid 식을 직접 작성할 경우 tf.math.log(hypothesis(X))의 처리에서 NaN문제가 발생하므로 tf.sigmoid()이용\n",
    "  z = tf.matmul(x,W) + b\n",
    "  return tf.sigmoid(z)\n",
    "print(hypothesis(X_tf).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WeHj3PT7Z06z"
   },
   "source": [
    "## Cross entropy\n",
    "\n",
    "* $\\displaystyle -\\sum_{i=1}^{n}[y_i \\log{H_i}+(1-y_i) \\log{(1-H_i)}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1668813652186,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "kUfBjLXxZwFX",
    "outputId": "65ea7d03-9f98-4f7e-9e61-b2121727c29a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.7355182, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def cost_function(H,Y):\n",
    "  # Cross entropy식\n",
    "  cost = -tf.reduce_mean(Y * tf.math.log(H) + (1-Y) * tf.math.log(1-H))\n",
    "  return cost\n",
    "\n",
    "#계산예시\n",
    "print(cost_function(hypothesis(X_tf), y_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61436,
     "status": "ok",
     "timestamp": 1668813714738,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "Om-qhNYKbYzD",
    "outputId": "6a4db1bc-4ff4-4bfb-c10e-7b6d0553539f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0, loss = 3.735518217086792\n",
      "step : 200, loss = 1.974420428276062\n",
      "step : 400, loss = 0.8843432664871216\n",
      "step : 600, loss = 0.4457279443740845\n",
      "step : 800, loss = 0.27286821603775024\n",
      "step : 1000, loss = 0.19097569584846497\n",
      "step : 1200, loss = 0.1454271823167801\n",
      "step : 1400, loss = 0.11705788969993591\n",
      "step : 1600, loss = 0.09792069345712662\n",
      "step : 1800, loss = 0.08423872292041779\n",
      "[[-1.1821468 ]\n",
      " [-0.70464057]\n",
      " [-2.0135825 ]\n",
      " [-0.4211797 ]\n",
      " [ 0.6181067 ]\n",
      " [-1.112518  ]\n",
      " [ 0.9087258 ]\n",
      " [-0.80097264]\n",
      " [ 0.41663662]\n",
      " [-0.7012064 ]\n",
      " [ 0.39710343]\n",
      " [ 0.47302255]\n",
      " [-0.69148326]\n",
      " [-0.4401329 ]\n",
      " [ 0.709804  ]\n",
      " [ 0.71355397]\n",
      " [-0.68897635]\n",
      " [-0.38721523]\n",
      " [ 0.79493725]\n",
      " [-1.3151577 ]\n",
      " [ 2.4592464 ]\n",
      " [ 0.0878381 ]\n",
      " [-1.2537979 ]\n",
      " [ 1.0616412 ]\n",
      " [-0.03789743]\n",
      " [ 1.1083618 ]\n",
      " [-0.01125089]\n",
      " [ 0.13240105]\n",
      " [ 0.9514579 ]]\n",
      "[0.37536126]\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameter setting\n",
    "learning_rate = .001\n",
    "optimizer = tf.optimizers.SGD(learning_rate)\n",
    "\n",
    "loss_hist = []\n",
    "for step in range(2000):\n",
    "  with tf.GradientTape() as tape:\n",
    "    pred = hypothesis(X_tf)\n",
    "    cost = cost_function(pred, y_tf)\n",
    "    gradients = tape.gradient(cost, [W,b])\n",
    "  optimizer.apply_gradients(zip(gradients, [W,b]))\n",
    "  \n",
    "  loss_hist.append(cost)\n",
    "\n",
    "  if step % 200 == 0:\n",
    "    print('step : {}, loss = {}'.format(step, cost.numpy()))\n",
    "print(W.numpy())\n",
    "print(b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "executionInfo": {
     "elapsed": 595,
     "status": "ok",
     "timestamp": 1668813715325,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "UPN_2cFzq5P1",
    "outputId": "9cf33d12-e380-4f1d-dd14-9fb0c0eb253d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(range(2000), loss_hist)\n",
    "plt.title('# of Iteration & Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1668773904441,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "u-mJ6GB-luAb",
    "outputId": "a80b151d-18fc-43ae-c4a5-0c134a29a1e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(284807, 1), dtype=float32, numpy=\n",
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_function(H):\n",
    "  return tf.cast(H > .5, dtype = tf.float32)\n",
    "predict_function(hypothesis(X_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1668773907387,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "fY1o3MvYnD4X",
    "outputId": "cad5df93-8f00-4aff-8118-28694ae664c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.9983\n",
      "precision score : 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall score : 0.0000\n",
      "f1 score : 0.0000\n"
     ]
    }
   ],
   "source": [
    "# sklearn의 metrics 이용하여 accuracy, precision, recall, f1-score 계산하기\n",
    "def print_score(y_true, y_pred):\n",
    "  from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "  print('accuracy score : {:.4f}'.format(accuracy_score(y_true, y_pred)))\n",
    "  print('precision score : {:.4f}'.format(precision_score(y_true, y_pred)))\n",
    "  print('recall score : {:.4f}'.format(recall_score(y_true, y_pred)))\n",
    "  print('f1 score : {:.4f}'.format(f1_score(y_true, y_pred)))\n",
    "\n",
    "print_score(y_tf, predict_function(hypothesis(X_tf)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 449,
     "status": "ok",
     "timestamp": 1668773928448,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "eR9sLBlNnkrC",
    "outputId": "4ec84e86-074c-4a5a-bbdb-8d6db5b052cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 약 28만개의 data 중 1로 예측한 개수\n",
    "predict_function(hypothesis(X_tf)).numpy().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKylDFc7YPLn"
   },
   "source": [
    "* scikit learn 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6079,
     "status": "ok",
     "timestamp": 1668773939859,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "Abs1tdOF4v_h",
    "outputId": "73c3bde9-4bf3-4bc4-cd0b-126ea72177f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(random_state = 5, max_iter = 100)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_prediction = logistic_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1668773939859,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "41xtL7IJ4OiS",
    "outputId": "8e8a658b-bfbe-469c-ea46-4ce065adbab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.9993\n",
      "precision score : 0.9302\n",
      "recall score : 0.6612\n",
      "f1 score : 0.7729\n"
     ]
    }
   ],
   "source": [
    "# accuracy, precision, recall, f1score 출력 함수 만들기\n",
    "def print_score(y_true, y_pred):\n",
    "  from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "  print('accuracy score : {:.4f}'.format(accuracy_score(y_true, y_pred)))\n",
    "  print('precision score : {:.4f}'.format(precision_score(y_true, y_pred)))\n",
    "  print('recall score : {:.4f}'.format(recall_score(y_true, y_pred)))\n",
    "  print('f1 score : {:.4f}'.format(f1_score(y_true, y_pred)))\n",
    "print_score(y_test,y_prediction)\n",
    "#accuracy_score(y_true = y_test, y_pred = y_prediction)\n",
    "#precision_score(y_true, y_pred)\n",
    "#recall_score(y_true, y_pred)\n",
    "#f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWBbXntNCYn3"
   },
   "source": [
    "* accuracy, precision score는 높지만 recall score(실제 Fraud인 observation 중 모델이 Fraud라고 예측한 비율)이 낮게 나타남\n",
    "\n",
    "* Tensorflow의 gradient descent를 이용해 직접 계산한 W, b로는 예측이 나빠진 원인?\n",
    " * Solver 차이?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B73qSkDj7DV2"
   },
   "outputs": [],
   "source": [
    "# imblearn 모듈을 이용한 imbalanced dataset 다루기\n",
    "# Oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1668774504098,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "h0UVTGRctVyz",
    "outputId": "b5bb02e4-d636-48ce-bea8-1625f45bb35f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set의 Fraud data 비율 : 0.0017\n"
     ]
    }
   ],
   "source": [
    "print('Training set의 Fraud data 비율 : {:.4f}'.format(sum(y_train) / len(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUbIRcIrtub2"
   },
   "source": [
    "## RandomOverSampler\n",
    "\n",
    "* target 데이터의 밸런스를 맞추기 위해 데이터 개수가 부족한 쪽을 oversampling 해줌.\n",
    "\n",
    "* $\\displaystyle  \\text{ratio of fraud data} = \\frac{\\text{sampling_strategy}}{(1 + \\text{sampling_strategy})}$\n",
    "\n",
    "* ex) $\\text{sampling_strategy} = 0.5$인 경우 oversampling한 데이터의 fraud data 비중은 $\\displaystyle \\frac{1}{3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 517,
     "status": "ok",
     "timestamp": 1668774429632,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "fFTh7P_t8S4u",
    "outputId": "e0653c78-9a26-4306-e619-3beecc7ad19f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 개수 비율: 0.004974335044330378\n",
      "1 개수 비율: 0.9950256649556696\n"
     ]
    }
   ],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy = 0.002, random_state = 5)\n",
    "\n",
    "X_train_over, y_train_over = oversample.fit_resample(X_train, y_train)\n",
    "print('0 개수 비율: {}'.format(sum(y_train_over) / len(y_train_over)))\n",
    "print('1 개수 비율: {}'.format((len(y_train_over) - sum(y_train_over)) / len(y_train_over)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8608,
     "status": "ok",
     "timestamp": 1668774438633,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "i1UzO5ON9idb",
    "outputId": "ab19a395-1253-4061-bcea-e2806bf12458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.9994\n",
      "precision score : 0.8440\n",
      "recall score : 0.7603\n",
      "f1 score : 0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(random_state = 5, max_iter = 100)\n",
    "logistic_model.fit(X_train_over, y_train_over)\n",
    "y_prediction = logistic_model.predict(X_test)\n",
    "print_score(y_test,y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64146,
     "status": "ok",
     "timestamp": 1668775842114,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "bYjKump_vI4b",
    "outputId": "0ea8b061-15d7-41f1-dc12-485251bbed37"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "# Grid Searching to find the best oversampling weight\n",
    "\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "sampling_strategies = [0.015, 0.002, 0.0025, 0.005, 0.01, 0.025, 0.05, 0.1, 0.2, 0.5]\n",
    "\n",
    "for sampling_strategy in sampling_strategies:\n",
    "  #oversampling\n",
    "  oversample = RandomOverSampler(sampling_strategy = sampling_strategy, random_state = 42)\n",
    "  X_train_over, y_train_over = oversample.fit_resample(X_train, y_train)\n",
    "\n",
    "  #Fitting logistic model\n",
    "  logistic_model = LogisticRegression(random_state = 5, max_iter = 100)\n",
    "  logistic_model.fit(X_train_over, y_train_over)\n",
    "  y_prediction = logistic_model.predict(X_test)\n",
    "  precision_scores.append(precision_score(y_test, y_prediction))\n",
    "  recall_scores.append(recall_score(y_test, y_prediction))\n",
    "  f1_scores.append(f1_score(y_test, y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "executionInfo": {
     "elapsed": 448,
     "status": "ok",
     "timestamp": 1668775966984,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "vOdHBjFtwHY0",
    "outputId": "f245e48e-4543-42d6-bbb4-35444aeda0ec"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "plt.plot(sampling_strategies, precision_scores, label = 'Precision score')\n",
    "plt.plot(sampling_strategies, recall_scores, label = 'Recall score')\n",
    "plt.plot(sampling_strategies, f1_scores, label = 'f1-score')\n",
    "plt.title('F1, Recall & Precision scores by oversampling weights')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 442,
     "status": "ok",
     "timestamp": 1668776121008,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "3FKKlcYvzIgl",
    "outputId": "34447ef3-e04e-4b3c-af63-80d7ec05cf24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score 최대 oversampling weight : 0.01\n"
     ]
    }
   ],
   "source": [
    "print('f1-score 최대 oversampling weight : {}'.format(sampling_strategies[np.array(f1_scores).argmax()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bwg9QkNFDQzw"
   },
   "source": [
    "* Oversampling 효과로 인해 precision score(Fraud라 예측한 것들 중 실제 Fraud 인 data의 비율)이 크게 떨어짐을 확인함\n",
    "\n",
    "\n",
    "* Recall score 상승 : 실제 Fraud 중에서 모형이 Fraud라고 detect한 데이터의 비중 상승\n",
    "\n",
    "\n",
    "* 그래프 확인 시 oversampling weight를 크게 늘릴 수록, recall score 상승효과보다 precision score 하락 효과가 더 커 f1-score는 작아지는 경향을 보이게 됨.\n",
    " * F1-score가 최대가 되는 oversampling weight값은 0.01\n",
    "\n",
    "\n",
    "* 그러나 기존 데이터의 fraud data비율이 0.00497 = 0.497%에 불과했다는 점을 고려하면, 약 $1/101 \\approx 1\\text{%} $의 oversampling weight를 주는 것이 f1-score 관점에서 성능향상이 있음을 확인할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvWHGY8z-RDM"
   },
   "source": [
    "* minmax scaler 적용하여 logistic regression 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1668776151353,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "Zm_RgT74-kId",
    "outputId": "d23d7351-834a-4673-f1d8-0703b9cc6a99"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8018b2ae-90cb-4f20-9e96-4cfc07c5d115\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.935192</td>\n",
       "      <td>0.766490</td>\n",
       "      <td>0.881365</td>\n",
       "      <td>0.313023</td>\n",
       "      <td>0.763439</td>\n",
       "      <td>0.267669</td>\n",
       "      <td>0.266815</td>\n",
       "      <td>0.786444</td>\n",
       "      <td>0.475312</td>\n",
       "      <td>0.510601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582942</td>\n",
       "      <td>0.561184</td>\n",
       "      <td>0.522992</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0.391253</td>\n",
       "      <td>0.585122</td>\n",
       "      <td>0.394557</td>\n",
       "      <td>0.418976</td>\n",
       "      <td>0.312697</td>\n",
       "      <td>0.005824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.978542</td>\n",
       "      <td>0.770067</td>\n",
       "      <td>0.840299</td>\n",
       "      <td>0.271797</td>\n",
       "      <td>0.766120</td>\n",
       "      <td>0.262192</td>\n",
       "      <td>0.264875</td>\n",
       "      <td>0.786298</td>\n",
       "      <td>0.453981</td>\n",
       "      <td>0.505267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579530</td>\n",
       "      <td>0.557840</td>\n",
       "      <td>0.480237</td>\n",
       "      <td>0.666938</td>\n",
       "      <td>0.336440</td>\n",
       "      <td>0.587290</td>\n",
       "      <td>0.446013</td>\n",
       "      <td>0.416345</td>\n",
       "      <td>0.313423</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.935217</td>\n",
       "      <td>0.753118</td>\n",
       "      <td>0.868141</td>\n",
       "      <td>0.268766</td>\n",
       "      <td>0.762329</td>\n",
       "      <td>0.281122</td>\n",
       "      <td>0.270177</td>\n",
       "      <td>0.788042</td>\n",
       "      <td>0.410603</td>\n",
       "      <td>0.513018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585855</td>\n",
       "      <td>0.565477</td>\n",
       "      <td>0.546030</td>\n",
       "      <td>0.678939</td>\n",
       "      <td>0.289354</td>\n",
       "      <td>0.559515</td>\n",
       "      <td>0.402727</td>\n",
       "      <td>0.415489</td>\n",
       "      <td>0.311911</td>\n",
       "      <td>0.014739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.941878</td>\n",
       "      <td>0.765304</td>\n",
       "      <td>0.868484</td>\n",
       "      <td>0.213661</td>\n",
       "      <td>0.765647</td>\n",
       "      <td>0.275559</td>\n",
       "      <td>0.266803</td>\n",
       "      <td>0.789434</td>\n",
       "      <td>0.414999</td>\n",
       "      <td>0.507585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578050</td>\n",
       "      <td>0.559734</td>\n",
       "      <td>0.510277</td>\n",
       "      <td>0.662607</td>\n",
       "      <td>0.223826</td>\n",
       "      <td>0.614245</td>\n",
       "      <td>0.389197</td>\n",
       "      <td>0.417669</td>\n",
       "      <td>0.314371</td>\n",
       "      <td>0.004807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.938617</td>\n",
       "      <td>0.776520</td>\n",
       "      <td>0.864251</td>\n",
       "      <td>0.269796</td>\n",
       "      <td>0.762975</td>\n",
       "      <td>0.263984</td>\n",
       "      <td>0.268968</td>\n",
       "      <td>0.782484</td>\n",
       "      <td>0.490950</td>\n",
       "      <td>0.524303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.561327</td>\n",
       "      <td>0.547271</td>\n",
       "      <td>0.663392</td>\n",
       "      <td>0.401270</td>\n",
       "      <td>0.566343</td>\n",
       "      <td>0.507497</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.317490</td>\n",
       "      <td>0.002724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8018b2ae-90cb-4f20-9e96-4cfc07c5d115')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-8018b2ae-90cb-4f20-9e96-4cfc07c5d115 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-8018b2ae-90cb-4f20-9e96-4cfc07c5d115');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  0.935192  0.766490  0.881365  0.313023  0.763439  0.267669  0.266815   \n",
       "1  0.978542  0.770067  0.840299  0.271797  0.766120  0.262192  0.264875   \n",
       "2  0.935217  0.753118  0.868141  0.268766  0.762329  0.281122  0.270177   \n",
       "3  0.941878  0.765304  0.868484  0.213661  0.765647  0.275559  0.266803   \n",
       "4  0.938617  0.776520  0.864251  0.269796  0.762975  0.263984  0.268968   \n",
       "\n",
       "         V8        V9       V10  ...       V20       V21       V22       V23  \\\n",
       "0  0.786444  0.475312  0.510601  ...  0.582942  0.561184  0.522992  0.663793   \n",
       "1  0.786298  0.453981  0.505267  ...  0.579530  0.557840  0.480237  0.666938   \n",
       "2  0.788042  0.410603  0.513018  ...  0.585855  0.565477  0.546030  0.678939   \n",
       "3  0.789434  0.414999  0.507585  ...  0.578050  0.559734  0.510277  0.662607   \n",
       "4  0.782484  0.490950  0.524303  ...  0.584615  0.561327  0.547271  0.663392   \n",
       "\n",
       "        V24       V25       V26       V27       V28    Amount  \n",
       "0  0.391253  0.585122  0.394557  0.418976  0.312697  0.005824  \n",
       "1  0.336440  0.587290  0.446013  0.416345  0.313423  0.000105  \n",
       "2  0.289354  0.559515  0.402727  0.415489  0.311911  0.014739  \n",
       "3  0.223826  0.614245  0.389197  0.417669  0.314371  0.004807  \n",
       "4  0.401270  0.566343  0.507497  0.420561  0.317490  0.002724  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHehCB8v-653"
   },
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, test_size = .25, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3239,
     "status": "ok",
     "timestamp": 1668776157675,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "Mknal4Ao_FUQ",
    "outputId": "53bdd21e-9a8a-4ca8-de3c-63ab80896d5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.9992\n",
      "precision score : 0.9079\n",
      "recall score : 0.5702\n",
      "f1 score : 0.7005\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(random_state = 5, max_iter = 100)\n",
    "logistic_model.fit(X_train_scaled, y_train)\n",
    "y_prediction = logistic_model.predict(X_test_scaled)\n",
    "print_score(y_test, y_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3BL_tysC_7x7"
   },
   "source": [
    "* Recall score가 낮아지며 MinMaxScaling을 적용하지 않았을 때보다 f1-score 측면에서 오히려 성능이 하락함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeSYnvETCgT6"
   },
   "source": [
    "## ANN\n",
    "\n",
    "* activation function ReLU, sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4KOLql_AfAa"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1668776161866,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "htcWQKHPBBZh",
    "outputId": "08f2d19b-1041-4904-f137-c4544fce9eff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                1500      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,651\n",
      "Trainable params: 6,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation = 'relu', input_dim = X.shape[1])) # input_dim : # of features\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90817,
     "status": "ok",
     "timestamp": 1668776257978,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "lWWMW-34BqOk",
    "outputId": "62fb2bc4-94c6-4583-cd4a-aaaf7cda6c82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3338/3338 [==============================] - 10s 3ms/step - loss: 0.0086 - accuracy: 0.9986\n",
      "Epoch 2/10\n",
      "3338/3338 [==============================] - 8s 2ms/step - loss: 0.0042 - accuracy: 0.9992\n",
      "Epoch 3/10\n",
      "3338/3338 [==============================] - 9s 3ms/step - loss: 0.0040 - accuracy: 0.9993\n",
      "Epoch 4/10\n",
      "3338/3338 [==============================] - 10s 3ms/step - loss: 0.0039 - accuracy: 0.9993\n",
      "Epoch 5/10\n",
      "3338/3338 [==============================] - 9s 3ms/step - loss: 0.0039 - accuracy: 0.9993\n",
      "Epoch 6/10\n",
      "3338/3338 [==============================] - 9s 3ms/step - loss: 0.0039 - accuracy: 0.9993\n",
      "Epoch 7/10\n",
      "3338/3338 [==============================] - 9s 3ms/step - loss: 0.0038 - accuracy: 0.9993\n",
      "Epoch 8/10\n",
      "3338/3338 [==============================] - 9s 3ms/step - loss: 0.0037 - accuracy: 0.9993\n",
      "Epoch 9/10\n",
      "3338/3338 [==============================] - 9s 3ms/step - loss: 0.0038 - accuracy: 0.9993\n",
      "Epoch 10/10\n",
      "3338/3338 [==============================] - 10s 3ms/step - loss: 0.0038 - accuracy: 0.9993\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "history = model.fit(X_train_scaled, y_train, epochs = 10, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5699,
     "status": "ok",
     "timestamp": 1668776275545,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "EMPycYlcBKi2",
    "outputId": "3ae5c80e-8471-4935-be93-66b4269c0809"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc : 0.99949\n"
     ]
    }
   ],
   "source": [
    "loss, train_acc = model.evaluate(X_test_scaled, y_test, verbose = 0)\n",
    "print('train acc : {:.5f}'.format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5653,
     "status": "ok",
     "timestamp": 1668776282322,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "TVquR8dXDRb7",
    "outputId": "cb115d75-424c-4d18-8495-c6424079f913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2226/2226 [==============================] - 3s 1ms/step\n",
      "accuracy score : 0.9995\n",
      "precision score : 0.8571\n",
      "recall score : 0.8430\n",
      "f1 score : 0.8500\n"
     ]
    }
   ],
   "source": [
    "y_prediction_ANN = model.predict(X_test_scaled) # [[0.87],[0.001], ... ]\n",
    "y_prediction_ANN = np.where(y_prediction_ANN.reshape(-1) > 0.5, 1., 0.)  # y_prediction_ANN의 각 원소가 []로 감싸져있으므로 reshape처리해야 where가 정상실행\n",
    "print_score(y_true = y_test, y_pred = y_prediction_ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ek9_O-9VFVJL"
   },
   "source": [
    "* Logistic regression을 이용한 예측보다 recall score 및 f1 score가 크게 향상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAb6uBo41Sil"
   },
   "source": [
    "# Dropout method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUJfu-3iHPz-"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 119667,
     "status": "ok",
     "timestamp": 1668776669508,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "zw0uyhzRIlPJ",
    "outputId": "800943aa-e245-41b1-86f6-06b1756146d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3338/3338 [==============================] - 12s 3ms/step - loss: 0.0149 - accuracy: 0.9975\n",
      "Epoch 2/10\n",
      "3338/3338 [==============================] - 11s 3ms/step - loss: 0.0073 - accuracy: 0.9984\n",
      "Epoch 3/10\n",
      "3338/3338 [==============================] - 12s 3ms/step - loss: 0.0068 - accuracy: 0.9990\n",
      "Epoch 4/10\n",
      "3338/3338 [==============================] - 13s 4ms/step - loss: 0.0064 - accuracy: 0.9990\n",
      "Epoch 5/10\n",
      "3338/3338 [==============================] - 11s 3ms/step - loss: 0.0057 - accuracy: 0.9990\n",
      "Epoch 6/10\n",
      "3338/3338 [==============================] - 13s 4ms/step - loss: 0.0059 - accuracy: 0.9990\n",
      "Epoch 7/10\n",
      "3338/3338 [==============================] - 11s 3ms/step - loss: 0.0057 - accuracy: 0.9991\n",
      "Epoch 8/10\n",
      "3338/3338 [==============================] - 12s 4ms/step - loss: 0.0055 - accuracy: 0.9991\n",
      "Epoch 9/10\n",
      "3338/3338 [==============================] - 12s 4ms/step - loss: 0.0055 - accuracy: 0.9991\n",
      "Epoch 10/10\n",
      "3338/3338 [==============================] - 11s 3ms/step - loss: 0.0057 - accuracy: 0.9990\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation = 'relu', input_dim = X.shape[1]))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "history = model.fit(X_train_scaled, y_train, epochs = 10, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5823,
     "status": "ok",
     "timestamp": 1668776682485,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "dw6oChXnJoKg",
    "outputId": "be20a364-2a17-4610-d111-07e15a4dbc7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2226/2226 [==============================] - 4s 2ms/step\n",
      "accuracy score : 0.9996\n",
      "precision score : 0.9083\n",
      "recall score : 0.8182\n",
      "f1 score : 0.8609\n"
     ]
    }
   ],
   "source": [
    "y_prediction_ANN = model.predict(X_test_scaled)\n",
    "y_prediction_ANN = np.where(y_prediction_ANN.reshape(-1) > 0.5, 1., 0.)  # y_prediction_ANN의 각 원소가 []로 감싸져있으므로 reshape처리해야 where가 정상실행\n",
    "print_score(y_true = y_test, y_pred = y_prediction_ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fm8g6CQTNrEc"
   },
   "source": [
    "## Note\n",
    "\n",
    "* Precision score : Fraud라고 예측한 것 중 실제로 Fraud인 것\n",
    "(실제 Fraud / (실제 Fraud + Fraud가 아니지만 Fraud라 예측))\n",
    "\n",
    "\n",
    "* Recall score : 실제 Fraud인 것 중 모형이 Fraud라 예측한 것\n",
    "\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "* Precision score 대비 Recall score가 낮게나오면서 전체적인 f1 score가 떨어짐..\n",
    " * $\\rightarrow$ 실제로 Fraud인 것을 모형이 Fraud라고 제대로 예측하지 못하고 정상거래라고 오인했다는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1DWRtNYOKXU"
   },
   "source": [
    "---\n",
    "## Early stopping method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60637,
     "status": "ok",
     "timestamp": 1668776831742,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "oeFWvUk3O_aL",
    "outputId": "544e4155-6c97-4a7d-89b3-a48240c24fa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1336/1336 [==============================] - 6s 4ms/step - loss: 0.0114 - accuracy: 0.9989 - val_loss: 0.0043 - val_accuracy: 0.9992\n",
      "Epoch 2/10\n",
      "1336/1336 [==============================] - 5s 4ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9992\n",
      "Epoch 3/10\n",
      "1336/1336 [==============================] - 5s 4ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
      "Epoch 4/10\n",
      "1336/1336 [==============================] - 5s 4ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 5/10\n",
      "1336/1336 [==============================] - 5s 4ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0048 - val_accuracy: 0.9991\n",
      "Epoch 6/10\n",
      "1336/1336 [==============================] - 5s 4ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0054 - val_accuracy: 0.9991\n",
      "Epoch 7/10\n",
      "1336/1336 [==============================] - 5s 4ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0044 - val_accuracy: 0.9992\n",
      "Epoch 8/10\n",
      "1336/1336 [==============================] - 6s 4ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
      "Epoch 9/10\n",
      "1336/1336 [==============================] - 6s 4ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
      "Epoch 10/10\n",
      "1336/1336 [==============================] - 5s 4ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "2226/2226 [==============================] - 4s 2ms/step\n",
      "accuracy score : 0.9996\n",
      "precision score : 0.9083\n",
      "recall score : 0.8182\n",
      "f1 score : 0.8609\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Without applying early stopping method\n",
    "\n",
    "# divide the training set into a training set and a validation set\n",
    "\n",
    "X_train_scaled, X_val_scaled, y_train, y_val = train_test_split(X_train_scaled, y_train, test_size = .2, random_state = 40)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation = 'relu', input_dim = X.shape[1]))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, validation_data = (X_val_scaled, y_val), epochs = 10, batch_size = 128)\n",
    "\n",
    "y_prediction_ANN = model.predict(X_test_scaled)\n",
    "y_prediction_ANN = np.where(y_prediction_ANN.reshape(-1) > 0.5, 1., 0.)  # y_prediction_ANN의 각 원소가 []로 감싸져있으므로 reshape처리해야 where가 정상실행\n",
    "print_score(y_true = y_test, y_pred = y_prediction_ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1668345316410,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "8deccY2fPpkl",
    "outputId": "df57dbf7-e7c3-443e-fa8c-52210dccf177"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.xlabel(\"The number of learning\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43232,
     "status": "ok",
     "timestamp": 1668345466111,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "0QJbsEaFPiqm",
    "outputId": "99fd62f9-5a6a-45a5-93ea-52ef50573304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1336/1336 [==============================] - 6s 4ms/step - loss: 0.0120 - accuracy: 0.9986 - val_loss: 0.0060 - val_accuracy: 0.9989\n",
      "Epoch 2/30\n",
      "1336/1336 [==============================] - 5s 4ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 3/30\n",
      "1336/1336 [==============================] - 6s 5ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.0054 - val_accuracy: 0.9991\n",
      "Epoch 4/30\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 5/30\n",
      "1336/1336 [==============================] - 5s 4ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 6/30\n",
      "1336/1336 [==============================] - 5s 4ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0045 - val_accuracy: 0.9993\n",
      "Epoch 7/30\n",
      "1336/1336 [==============================] - 5s 4ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
      "Epoch 7: early stopping\n",
      "2226/2226 [==============================] - 3s 1ms/step\n",
      "accuracy score : 0.9995\n",
      "precision score : 0.8929\n",
      "recall score : 0.8264\n",
      "f1 score : 0.8584\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation = 'relu', input_dim = X.shape[1]))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 3)\n",
    "history = model.fit(X_train_scaled, y_train, validation_data = (X_val_scaled, y_val), epochs = 30, batch_size = 128, callbacks = [es])\n",
    "\n",
    "y_prediction_ANN = model.predict(X_test_scaled)\n",
    "y_prediction_ANN = np.where(y_prediction_ANN.reshape(-1) > 0.5, 1., 0.)  # y_prediction_ANN의 각 원소가 []로 감싸져있으므로 reshape처리해야 where가 정상실행\n",
    "print_score(y_true = y_test, y_pred = y_prediction_ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1668345549321,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "Jp9zpIN4R7Pt",
    "outputId": "80abfde2-5c7b-45d8-a956-b94affb30884"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.xlabel(\"The number of learning\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 228419,
     "status": "ok",
     "timestamp": 1668778493917,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "AnVUvfVxSAWb",
    "outputId": "81f6efe5-68d8-46f0-e78e-e36fb6835227"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2671/2671 [==============================] - 17s 6ms/step - loss: 0.0135 - accuracy: 0.9981 - val_loss: 0.0045 - val_accuracy: 0.9983\n",
      "Epoch 2/30\n",
      "2671/2671 [==============================] - 12s 4ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0043 - val_accuracy: 0.9990\n",
      "Epoch 3/30\n",
      "2671/2671 [==============================] - 11s 4ms/step - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.0045 - val_accuracy: 0.9991\n",
      "Epoch 4/30\n",
      "2671/2671 [==============================] - 12s 4ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.0069 - val_accuracy: 0.9990\n",
      "Epoch 5/30\n",
      "2671/2671 [==============================] - 11s 4ms/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 0.0058 - val_accuracy: 0.9991\n",
      "Epoch 6/30\n",
      "2671/2671 [==============================] - 13s 5ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.0051 - val_accuracy: 0.9991\n",
      "Epoch 7/30\n",
      "2671/2671 [==============================] - 11s 4ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
      "Epoch 8/30\n",
      "2671/2671 [==============================] - 11s 4ms/step - loss: 0.0048 - accuracy: 0.9993 - val_loss: 0.0053 - val_accuracy: 0.9992\n",
      "Epoch 9/30\n",
      "2671/2671 [==============================] - 10s 4ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9992\n",
      "Epoch 10/30\n",
      "2671/2671 [==============================] - 11s 4ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.0047 - val_accuracy: 0.9991\n",
      "Epoch 11/30\n",
      "2671/2671 [==============================] - 13s 5ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 0.0043 - val_accuracy: 0.9992\n",
      "Epoch 12/30\n",
      "2671/2671 [==============================] - 11s 4ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
      "Epoch 13/30\n",
      "2671/2671 [==============================] - 11s 4ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0037 - val_accuracy: 0.9992\n",
      "Epoch 14/30\n",
      "2671/2671 [==============================] - 11s 4ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 15/30\n",
      "2671/2671 [==============================] - 11s 4ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0036 - val_accuracy: 0.9992\n",
      "Epoch 16/30\n",
      "2671/2671 [==============================] - 14s 5ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 0.0043 - val_accuracy: 0.9992\n",
      "Epoch 17/30\n",
      "2671/2671 [==============================] - 11s 4ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "Epoch 18/30\n",
      "2671/2671 [==============================] - 12s 5ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.0037 - val_accuracy: 0.9992\n",
      "Epoch 19/30\n",
      "2671/2671 [==============================] - 11s 4ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 19: early stopping\n",
      "2226/2226 [==============================] - 4s 2ms/step\n",
      "accuracy score : 0.9996\n",
      "precision score : 0.9009\n",
      "recall score : 0.8264\n",
      "f1 score : 0.8621\n"
     ]
    }
   ],
   "source": [
    "# Dropout + EarlyStopping\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation = 'relu', input_dim = X.shape[1]))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 5)\n",
    "history = model.fit(X_train_scaled, y_train, validation_data = (X_val_scaled, y_val), epochs = 30, batch_size = 64, callbacks = [es])\n",
    "\n",
    "y_prediction_ANN = model.predict(X_test_scaled)\n",
    "y_prediction_ANN = np.where(y_prediction_ANN.reshape(-1) > 0.5, 1., 0.)  # y_prediction_ANN의 각 원소가 []로 감싸져있으므로 reshape처리해야 where가 정상실행\n",
    "print_score(y_true = y_test, y_pred = y_prediction_ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B11O4qaBOtzF"
   },
   "source": [
    "* Weight balancing\n",
    "cf : https://3months.tistory.com/414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1668347068995,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "yuSe7FsHO7te",
    "outputId": "a774b6c9-70e7-4e88-f0da-5be62dbee551"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001727485630620034"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 387779,
     "status": "ok",
     "timestamp": 1668778939875,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "RQCjXnO_OrFd",
    "outputId": "45b70bb4-6e0c-4a92-9b75-d70c114f7438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "668/668 [==============================] - 5s 6ms/step - loss: 0.0333 - accuracy: 0.9974 - val_loss: 0.0047 - val_accuracy: 0.9983\n",
      "Epoch 2/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0119 - accuracy: 0.9991 - val_loss: 0.0044 - val_accuracy: 0.9992\n",
      "Epoch 3/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0097 - accuracy: 0.9992 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 4/100\n",
      "668/668 [==============================] - 5s 7ms/step - loss: 0.0094 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 0.9992\n",
      "Epoch 5/100\n",
      "668/668 [==============================] - 4s 7ms/step - loss: 0.0090 - accuracy: 0.9992 - val_loss: 0.0044 - val_accuracy: 0.9990\n",
      "Epoch 6/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0088 - accuracy: 0.9993 - val_loss: 0.0043 - val_accuracy: 0.9991\n",
      "Epoch 7/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0087 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 8/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0087 - accuracy: 0.9991 - val_loss: 0.0060 - val_accuracy: 0.9984\n",
      "Epoch 9/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0091 - accuracy: 0.9991 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
      "Epoch 10/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0083 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 11/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
      "Epoch 12/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0091 - accuracy: 0.9992 - val_loss: 0.0050 - val_accuracy: 0.9991\n",
      "Epoch 13/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0083 - accuracy: 0.9993 - val_loss: 0.0045 - val_accuracy: 0.9989\n",
      "Epoch 14/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 15/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0082 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
      "Epoch 16/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0082 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 17/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0074 - accuracy: 0.9993 - val_loss: 0.0043 - val_accuracy: 0.9992\n",
      "Epoch 18/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 0.9991\n",
      "Epoch 19/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0078 - accuracy: 0.9993 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 20/100\n",
      "668/668 [==============================] - 5s 8ms/step - loss: 0.0077 - accuracy: 0.9993 - val_loss: 0.0054 - val_accuracy: 0.9992\n",
      "Epoch 21/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0080 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 22/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0077 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 23/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0083 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 24/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 25/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0075 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 26/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 27/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
      "Epoch 28/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0074 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 29/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0077 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 30/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0077 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
      "Epoch 31/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0078 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
      "Epoch 32/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0076 - accuracy: 0.9994 - val_loss: 0.0043 - val_accuracy: 0.9992\n",
      "Epoch 33/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0074 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 34/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0078 - accuracy: 0.9993 - val_loss: 0.0043 - val_accuracy: 0.9991\n",
      "Epoch 35/100\n",
      "668/668 [==============================] - 5s 8ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 36/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 0.0055 - val_accuracy: 0.9993\n",
      "Epoch 37/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0074 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 38/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0075 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
      "Epoch 39/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 40/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 41/100\n",
      "668/668 [==============================] - 5s 8ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "Epoch 42/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0071 - accuracy: 0.9993 - val_loss: 0.0044 - val_accuracy: 0.9993\n",
      "Epoch 43/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0079 - accuracy: 0.9993 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 44/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0073 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 45/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
      "Epoch 46/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 47/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0071 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
      "Epoch 48/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0071 - accuracy: 0.9993 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 49/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0070 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 50/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0069 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 51/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0075 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 52/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0075 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 53/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "Epoch 54/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0071 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 55/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 56/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0071 - accuracy: 0.9994 - val_loss: 0.0042 - val_accuracy: 0.9994\n",
      "Epoch 57/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "Epoch 58/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 59/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9994\n",
      "Epoch 60/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
      "Epoch 61/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "Epoch 62/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 63/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
      "Epoch 64/100\n",
      "668/668 [==============================] - 3s 5ms/step - loss: 0.0074 - accuracy: 0.9994 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "Epoch 65/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 66/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0073 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
      "Epoch 67/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0070 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 68/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0074 - accuracy: 0.9993 - val_loss: 0.0052 - val_accuracy: 0.9991\n",
      "Epoch 69/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0068 - accuracy: 0.9993 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 70/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 71/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0075 - accuracy: 0.9993 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 72/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 73/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0071 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
      "Epoch 74/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.0051 - val_accuracy: 0.9988\n",
      "Epoch 75/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0075 - accuracy: 0.9993 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "Epoch 76/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0070 - accuracy: 0.9993 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "Epoch 77/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "Epoch 78/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0071 - accuracy: 0.9994 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "Epoch 79/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
      "Epoch 80/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 81/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 82/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0071 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "Epoch 83/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "Epoch 84/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9995\n",
      "Epoch 85/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "Epoch 86/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "Epoch 87/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0074 - accuracy: 0.9993 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 88/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "Epoch 89/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
      "Epoch 90/100\n",
      "668/668 [==============================] - 4s 5ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 91/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0066 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
      "Epoch 92/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
      "Epoch 93/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0069 - accuracy: 0.9993 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "Epoch 94/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "Epoch 95/100\n",
      "668/668 [==============================] - 4s 7ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9995\n",
      "Epoch 96/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
      "Epoch 97/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.0045 - val_accuracy: 0.9994\n",
      "Epoch 98/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0068 - accuracy: 0.9993 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "Epoch 99/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "Epoch 100/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "2226/2226 [==============================] - 4s 2ms/step\n",
      "accuracy score : 0.9996\n",
      "precision score : 0.9027\n",
      "recall score : 0.8430\n",
      "f1 score : 0.8718\n"
     ]
    }
   ],
   "source": [
    "# Dropout + EarlyStopping + Weight\n",
    "#class_weight = {0. : sum(y) / len(y), 1. : 1 - sum(y) / len(y)}\n",
    "\n",
    "# 학습시 Fraud data에 2.5배의 weight를 부여함\n",
    "class_weight = {0. : 1, 1. : 2.5}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation = 'relu', input_dim = X.shape[1]))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 5)\n",
    "history = model.fit(X_train_scaled, y_train, validation_data = (X_val_scaled, y_val), epochs = 100, batch_size = 256, class_weight = class_weight)\n",
    "\n",
    "y_prediction_ANN = model.predict(X_test_scaled)\n",
    "y_prediction_ANN = np.where(y_prediction_ANN.reshape(-1) > 0.5, 1., 0.)  # y_prediction_ANN의 각 원소가 []로 감싸져있으므로 reshape처리해야 where가 정상실행\n",
    "print_score(y_true = y_test, y_pred = y_prediction_ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 438984,
     "status": "ok",
     "timestamp": 1668779705536,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "cZqTSLVGY_B6",
    "outputId": "e5238724-9524-4cd4-db48-1dbdfce44615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "668/668 [==============================] - 6s 8ms/step - loss: 0.0432 - accuracy: 0.9953 - val_loss: 0.0063 - val_accuracy: 0.9983\n",
      "Epoch 2/100\n",
      "668/668 [==============================] - 6s 8ms/step - loss: 0.0146 - accuracy: 0.9982 - val_loss: 0.0059 - val_accuracy: 0.9983\n",
      "Epoch 3/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0138 - accuracy: 0.9986 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Epoch 4/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0137 - accuracy: 0.9991 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
      "Epoch 5/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0127 - accuracy: 0.9992 - val_loss: 0.0045 - val_accuracy: 0.9993\n",
      "Epoch 6/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0124 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
      "Epoch 7/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0121 - accuracy: 0.9993 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 8/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0114 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 9/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0120 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 10/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0122 - accuracy: 0.9992 - val_loss: 0.0055 - val_accuracy: 0.9990\n",
      "Epoch 11/100\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 0.0117 - accuracy: 0.9991 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
      "Epoch 12/100\n",
      "668/668 [==============================] - 6s 10ms/step - loss: 0.0116 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 13/100\n",
      "668/668 [==============================] - 8s 12ms/step - loss: 0.0108 - accuracy: 0.9991 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 14/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0107 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9992\n",
      "Epoch 15/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0114 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
      "Epoch 16/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0112 - accuracy: 0.9991 - val_loss: 0.0043 - val_accuracy: 0.9989\n",
      "Epoch 17/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0108 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 18/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0115 - accuracy: 0.9991 - val_loss: 0.0049 - val_accuracy: 0.9992\n",
      "Epoch 19/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0107 - accuracy: 0.9992 - val_loss: 0.0051 - val_accuracy: 0.9984\n",
      "Epoch 20/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0099 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
      "Epoch 21/100\n",
      "668/668 [==============================] - 5s 7ms/step - loss: 0.0102 - accuracy: 0.9992 - val_loss: 0.0062 - val_accuracy: 0.9992\n",
      "Epoch 22/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0113 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 23/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0108 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9992\n",
      "Epoch 24/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0110 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
      "Epoch 25/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0097 - accuracy: 0.9993 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "Epoch 26/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0109 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 27/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0092 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 0.9991\n",
      "Epoch 28/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0094 - accuracy: 0.9992 - val_loss: 0.0049 - val_accuracy: 0.9993\n",
      "Epoch 29/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0103 - accuracy: 0.9992 - val_loss: 0.0049 - val_accuracy: 0.9992\n",
      "Epoch 30/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0101 - accuracy: 0.9991 - val_loss: 0.0055 - val_accuracy: 0.9985\n",
      "Epoch 31/100\n",
      "668/668 [==============================] - 5s 7ms/step - loss: 0.0105 - accuracy: 0.9992 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 32/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0101 - accuracy: 0.9991 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
      "Epoch 33/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0101 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 34/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0096 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
      "Epoch 35/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0099 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 36/100\n",
      "668/668 [==============================] - 6s 9ms/step - loss: 0.0102 - accuracy: 0.9992 - val_loss: 0.0056 - val_accuracy: 0.9985\n",
      "Epoch 37/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0106 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
      "Epoch 38/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0091 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9992\n",
      "Epoch 39/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0103 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
      "Epoch 40/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0096 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9991\n",
      "Epoch 41/100\n",
      "668/668 [==============================] - 4s 7ms/step - loss: 0.0098 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 42/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0090 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9991\n",
      "Epoch 43/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0098 - accuracy: 0.9993 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 44/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0096 - accuracy: 0.9993 - val_loss: 0.0054 - val_accuracy: 0.9993\n",
      "Epoch 45/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0109 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
      "Epoch 46/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0093 - accuracy: 0.9993 - val_loss: 0.0048 - val_accuracy: 0.9990\n",
      "Epoch 47/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0098 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 48/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0092 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 49/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0095 - accuracy: 0.9993 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 50/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0091 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9992\n",
      "Epoch 51/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0096 - accuracy: 0.9993 - val_loss: 0.0045 - val_accuracy: 0.9993\n",
      "Epoch 52/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0102 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9991\n",
      "Epoch 53/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0090 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9991\n",
      "Epoch 54/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0097 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9992\n",
      "Epoch 55/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0094 - accuracy: 0.9993 - val_loss: 0.0050 - val_accuracy: 0.9992\n",
      "Epoch 56/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0097 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
      "Epoch 57/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0101 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
      "Epoch 58/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0093 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 59/100\n",
      "668/668 [==============================] - 5s 7ms/step - loss: 0.0102 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
      "Epoch 60/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0097 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 61/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0097 - accuracy: 0.9993 - val_loss: 0.0052 - val_accuracy: 0.9991\n",
      "Epoch 62/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0098 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 63/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0098 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 64/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0090 - accuracy: 0.9993 - val_loss: 0.0050 - val_accuracy: 0.9993\n",
      "Epoch 65/100\n",
      "668/668 [==============================] - 4s 7ms/step - loss: 0.0094 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9992\n",
      "Epoch 66/100\n",
      "668/668 [==============================] - 4s 7ms/step - loss: 0.0109 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 67/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0089 - accuracy: 0.9993 - val_loss: 0.0037 - val_accuracy: 0.9992\n",
      "Epoch 68/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 0.0045 - val_accuracy: 0.9993\n",
      "Epoch 69/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0087 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 70/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0100 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 71/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0103 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 72/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0091 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 73/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 74/100\n",
      "668/668 [==============================] - 4s 7ms/step - loss: 0.0094 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9992\n",
      "Epoch 75/100\n",
      "668/668 [==============================] - 4s 7ms/step - loss: 0.0090 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 76/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 77/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0093 - accuracy: 0.9993 - val_loss: 0.0050 - val_accuracy: 0.9992\n",
      "Epoch 78/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0088 - accuracy: 0.9993 - val_loss: 0.0046 - val_accuracy: 0.9991\n",
      "Epoch 79/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0086 - accuracy: 0.9993 - val_loss: 0.0046 - val_accuracy: 0.9991\n",
      "Epoch 80/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0090 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 81/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0090 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
      "Epoch 82/100\n",
      "668/668 [==============================] - 4s 7ms/step - loss: 0.0092 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
      "Epoch 83/100\n",
      "668/668 [==============================] - 5s 7ms/step - loss: 0.0095 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 84/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0091 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 85/100\n",
      "668/668 [==============================] - 5s 7ms/step - loss: 0.0097 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 86/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0089 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 87/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0090 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 88/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0093 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9992\n",
      "Epoch 89/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0094 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 90/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0091 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9992\n",
      "Epoch 91/100\n",
      "668/668 [==============================] - 4s 7ms/step - loss: 0.0087 - accuracy: 0.9993 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "Epoch 92/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0093 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 93/100\n",
      "668/668 [==============================] - 4s 7ms/step - loss: 0.0095 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 94/100\n",
      "668/668 [==============================] - 5s 8ms/step - loss: 0.0088 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 95/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0088 - accuracy: 0.9994 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 96/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0086 - accuracy: 0.9993 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 97/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0086 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 98/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0086 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 99/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0087 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9992\n",
      "Epoch 100/100\n",
      "668/668 [==============================] - 4s 6ms/step - loss: 0.0094 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "2226/2226 [==============================] - 4s 2ms/step\n",
      "accuracy score : 0.9995\n",
      "precision score : 0.8571\n",
      "recall score : 0.8430\n",
      "f1 score : 0.8500\n"
     ]
    }
   ],
   "source": [
    "# Dropout + EarlyStopping + Weight\n",
    "#class_weight = {0. : sum(y) / len(y), 1. : 1 - sum(y) / len(y)}\n",
    "\n",
    "# 학습시 Fraud data에 3배의 weight를 부여함\n",
    "class_weight = {0. : 1, 1. : 3}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation = 'relu', input_dim = X.shape[1]))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 5)\n",
    "history = model.fit(X_train_scaled, y_train, validation_data = (X_val_scaled, y_val), epochs = 100, batch_size = 256, class_weight = class_weight)\n",
    "\n",
    "y_prediction_ANN = model.predict(X_test_scaled)\n",
    "y_prediction_ANN = np.where(y_prediction_ANN.reshape(-1) > 0.5, 1., 0.)  # y_prediction_ANN의 각 원소가 []로 감싸져있으므로 reshape처리해야 where가 정상실행\n",
    "print_score(y_true = y_test, y_pred = y_prediction_ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 765667,
     "status": "ok",
     "timestamp": 1668780983795,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "KuCg8ue8a7F2",
    "outputId": "5e4b54f0-21a1-4e03-a7fe-5303c0a8e908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1336/1336 [==============================] - 8s 6ms/step - loss: 0.0251 - accuracy: 0.9980 - val_loss: 0.0048 - val_accuracy: 0.9983\n",
      "Epoch 2/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0109 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9983\n",
      "Epoch 3/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0113 - accuracy: 0.9986 - val_loss: 0.0049 - val_accuracy: 0.9991\n",
      "Epoch 4/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0109 - accuracy: 0.9990 - val_loss: 0.0043 - val_accuracy: 0.9991\n",
      "Epoch 5/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0100 - accuracy: 0.9991 - val_loss: 0.0127 - val_accuracy: 0.9966\n",
      "Epoch 6/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0093 - accuracy: 0.9991 - val_loss: 0.0046 - val_accuracy: 0.9991\n",
      "Epoch 7/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0102 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
      "Epoch 8/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0100 - accuracy: 0.9990 - val_loss: 0.0056 - val_accuracy: 0.9991\n",
      "Epoch 9/100\n",
      "1336/1336 [==============================] - 7s 6ms/step - loss: 0.0087 - accuracy: 0.9992 - val_loss: 0.0052 - val_accuracy: 0.9991\n",
      "Epoch 10/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0096 - accuracy: 0.9992 - val_loss: 0.0058 - val_accuracy: 0.9991\n",
      "Epoch 11/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0097 - accuracy: 0.9991 - val_loss: 0.0045 - val_accuracy: 0.9991\n",
      "Epoch 12/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0091 - accuracy: 0.9991 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 13/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0088 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 14/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0101 - accuracy: 0.9990 - val_loss: 0.0049 - val_accuracy: 0.9987\n",
      "Epoch 15/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0099 - accuracy: 0.9991 - val_loss: 0.0077 - val_accuracy: 0.9991\n",
      "Epoch 16/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0098 - accuracy: 0.9992 - val_loss: 0.0044 - val_accuracy: 0.9989\n",
      "Epoch 17/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0092 - accuracy: 0.9991 - val_loss: 0.0040 - val_accuracy: 0.9991\n",
      "Epoch 18/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0090 - accuracy: 0.9991 - val_loss: 0.0053 - val_accuracy: 0.9985\n",
      "Epoch 19/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0094 - accuracy: 0.9990 - val_loss: 0.0044 - val_accuracy: 0.9989\n",
      "Epoch 20/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0094 - accuracy: 0.9991 - val_loss: 0.0043 - val_accuracy: 0.9991\n",
      "Epoch 21/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0090 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 0.9991\n",
      "Epoch 22/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0083 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
      "Epoch 23/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0087 - accuracy: 0.9991 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
      "Epoch 24/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0081 - accuracy: 0.9991 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
      "Epoch 25/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0083 - accuracy: 0.9992 - val_loss: 0.0046 - val_accuracy: 0.9989\n",
      "Epoch 26/100\n",
      "1336/1336 [==============================] - 9s 7ms/step - loss: 0.0084 - accuracy: 0.9991 - val_loss: 0.0043 - val_accuracy: 0.9991\n",
      "Epoch 27/100\n",
      "1336/1336 [==============================] - 7s 6ms/step - loss: 0.0079 - accuracy: 0.9991 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
      "Epoch 28/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0088 - accuracy: 0.9991 - val_loss: 0.0047 - val_accuracy: 0.9989\n",
      "Epoch 29/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0087 - accuracy: 0.9991 - val_loss: 0.0045 - val_accuracy: 0.9991\n",
      "Epoch 30/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0084 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 0.9992\n",
      "Epoch 31/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0080 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 32/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0079 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 33/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0074 - accuracy: 0.9993 - val_loss: 0.0218 - val_accuracy: 0.9989\n",
      "Epoch 34/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0094 - accuracy: 0.9991 - val_loss: 0.0061 - val_accuracy: 0.9991\n",
      "Epoch 35/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9992\n",
      "Epoch 36/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 0.9992\n",
      "Epoch 37/100\n",
      "1336/1336 [==============================] - 8s 6ms/step - loss: 0.0079 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 0.9991\n",
      "Epoch 38/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0080 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "Epoch 39/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0077 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 40/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 0.9991\n",
      "Epoch 41/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0079 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 42/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0077 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
      "Epoch 43/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0083 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
      "Epoch 44/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0082 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "Epoch 45/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0078 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
      "Epoch 46/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0076 - accuracy: 0.9991 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "Epoch 47/100\n",
      "1336/1336 [==============================] - 8s 6ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.0052 - val_accuracy: 0.9990\n",
      "Epoch 48/100\n",
      "1336/1336 [==============================] - 7s 6ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
      "Epoch 49/100\n",
      "1336/1336 [==============================] - 7s 6ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.0050 - val_accuracy: 0.9992\n",
      "Epoch 50/100\n",
      "1336/1336 [==============================] - 7s 6ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
      "Epoch 51/100\n",
      "1336/1336 [==============================] - 7s 6ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 52/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "Epoch 53/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0079 - accuracy: 0.9991 - val_loss: 0.0045 - val_accuracy: 0.9991\n",
      "Epoch 54/100\n",
      "1336/1336 [==============================] - 7s 6ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.0047 - val_accuracy: 0.9993\n",
      "Epoch 55/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0074 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 56/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 57/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0078 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 0.9991\n",
      "Epoch 58/100\n",
      "1336/1336 [==============================] - 8s 6ms/step - loss: 0.0079 - accuracy: 0.9991 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 59/100\n",
      "1336/1336 [==============================] - 8s 6ms/step - loss: 0.0077 - accuracy: 0.9992 - val_loss: 0.0052 - val_accuracy: 0.9988\n",
      "Epoch 60/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0069 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 61/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 62/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.0044 - val_accuracy: 0.9993\n",
      "Epoch 63/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0071 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 64/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "Epoch 65/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0078 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 0.9991\n",
      "Epoch 66/100\n",
      "1336/1336 [==============================] - 9s 7ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.0046 - val_accuracy: 0.9993\n",
      "Epoch 67/100\n",
      "1336/1336 [==============================] - 10s 7ms/step - loss: 0.0102 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 68/100\n",
      "1336/1336 [==============================] - 8s 6ms/step - loss: 0.0069 - accuracy: 0.9993 - val_loss: 0.0052 - val_accuracy: 0.9993\n",
      "Epoch 69/100\n",
      "1336/1336 [==============================] - 7s 6ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 70/100\n",
      "1336/1336 [==============================] - 8s 6ms/step - loss: 0.0070 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 71/100\n",
      "1336/1336 [==============================] - 9s 7ms/step - loss: 0.0069 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 72/100\n",
      "1336/1336 [==============================] - 11s 8ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9992\n",
      "Epoch 73/100\n",
      "1336/1336 [==============================] - 11s 9ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 74/100\n",
      "1336/1336 [==============================] - 9s 7ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 75/100\n",
      "1336/1336 [==============================] - 8s 6ms/step - loss: 0.0077 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 76/100\n",
      "1336/1336 [==============================] - 10s 8ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9992\n",
      "Epoch 77/100\n",
      "1336/1336 [==============================] - 10s 8ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9992\n",
      "Epoch 78/100\n",
      "1336/1336 [==============================] - 10s 8ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 79/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 80/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0068 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 81/100\n",
      "1336/1336 [==============================] - 9s 6ms/step - loss: 0.0068 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 82/100\n",
      "1336/1336 [==============================] - 10s 8ms/step - loss: 0.0068 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 83/100\n",
      "1336/1336 [==============================] - 10s 7ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 0.9991\n",
      "Epoch 84/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
      "Epoch 85/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0080 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 86/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0080 - accuracy: 0.9993 - val_loss: 0.0108 - val_accuracy: 0.9993\n",
      "Epoch 87/100\n",
      "1336/1336 [==============================] - 9s 7ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 88/100\n",
      "1336/1336 [==============================] - 7s 6ms/step - loss: 0.0068 - accuracy: 0.9993 - val_loss: 0.0078 - val_accuracy: 0.9993\n",
      "Epoch 89/100\n",
      "1336/1336 [==============================] - 8s 6ms/step - loss: 0.0077 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 90/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 91/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 92/100\n",
      "1336/1336 [==============================] - 8s 6ms/step - loss: 0.0079 - accuracy: 0.9992 - val_loss: 0.0044 - val_accuracy: 0.9992\n",
      "Epoch 93/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0078 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 94/100\n",
      "1336/1336 [==============================] - 7s 6ms/step - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9992\n",
      "Epoch 95/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 96/100\n",
      "1336/1336 [==============================] - 7s 6ms/step - loss: 0.0069 - accuracy: 0.9993 - val_loss: 0.0045 - val_accuracy: 0.9993\n",
      "Epoch 97/100\n",
      "1336/1336 [==============================] - 8s 6ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 98/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0071 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 99/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0068 - accuracy: 0.9993 - val_loss: 0.0044 - val_accuracy: 0.9992\n",
      "Epoch 100/100\n",
      "1336/1336 [==============================] - 7s 5ms/step - loss: 0.0074 - accuracy: 0.9993 - val_loss: 0.0070 - val_accuracy: 0.9992\n",
      "2226/2226 [==============================] - 4s 2ms/step\n",
      "accuracy score : 0.9995\n",
      "precision score : 0.9048\n",
      "recall score : 0.7851\n",
      "f1 score : 0.8407\n"
     ]
    }
   ],
   "source": [
    "# Dropout + EarlyStopping + Weight\n",
    "#class_weight = {0. : sum(y) / len(y), 1. : 1 - sum(y) / len(y)}\n",
    "\n",
    "# 학습시 Fraud data에 2배의 weight를 부여함\n",
    "class_weight = {0. : 1, 1. : 2}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation = 'relu', input_dim = X.shape[1]))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 5)\n",
    "history = model.fit(X_train_scaled, y_train, validation_data = (X_val_scaled, y_val), epochs = 100, batch_size = 128, class_weight = class_weight)\n",
    "\n",
    "y_prediction_ANN = model.predict(X_test_scaled)\n",
    "y_prediction_ANN = np.where(y_prediction_ANN.reshape(-1) > 0.5, 1., 0.)  # y_prediction_ANN의 각 원소가 []로 감싸져있으므로 reshape처리해야 where가 정상실행\n",
    "print_score(y_true = y_test, y_pred = y_prediction_ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 414,
     "status": "ok",
     "timestamp": 1668780994149,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "JcQcMnQkS0J7",
    "outputId": "acd1736c-3c5f-4395-ab4f-568452302d6f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.xlabel(\"The number of learning\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NggdHSX5TrKc"
   },
   "source": [
    "## Variable Selection\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VUeS9tszT1NW"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38065,
     "status": "ok",
     "timestamp": 1668781717978,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "VGtFQ4SmT38h",
    "outputId": "8b247b7f-ee72-4994-f106-3c9648f4cc54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.9996\n",
      "precision score : 0.9596\n",
      "recall score : 0.7851\n",
      "f1 score : 0.8636\n"
     ]
    }
   ],
   "source": [
    "# Validation set 만들면서 Training set개수 줄어들었던 것 복구\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, test_size = .25, random_state = 40)\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators = 50, max_depth = 5, random_state = 5)\n",
    "model_rf.fit(X_train_scaled, y_train)\n",
    "rf_prediction = model_rf.predict(X_test_scaled)\n",
    "print_score(y_test, rf_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41354,
     "status": "ok",
     "timestamp": 1668781873559,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "wspA9KD8NMg7",
    "outputId": "a786adee-fe37-4eff-bd44-f8d2c4a9a58a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.9995\n",
      "precision score : 0.8729\n",
      "recall score : 0.8512\n",
      "f1 score : 0.8619\n"
     ]
    }
   ],
   "source": [
    "# oversampling\n",
    "model_rf = RandomForestClassifier(n_estimators = 50, max_depth = 5, random_state = 5)\n",
    "oversample = RandomOverSampler(sampling_strategy = 0.025, random_state = 5)\n",
    "X_train_over, y_train_over = oversample.fit_resample(X_train_scaled, y_train)\n",
    "model_rf.fit(X_train_over, y_train_over)\n",
    "rf_prediction = model_rf.predict(X_test_scaled)\n",
    "print_score(y_test, rf_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 624,
     "status": "ok",
     "timestamp": 1668781892890,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "ysT33ZZmVOrS",
    "outputId": "57e7efcc-48d0-43b6-978b-3ddfaf1a7743"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00408407 0.00347991 0.04344261 0.05224989 0.00184435 0.01017887\n",
      " 0.00997738 0.00222614 0.03296547 0.18354044 0.06441764 0.11550203\n",
      " 0.00082348 0.21310039 0.00034033 0.06569343 0.13789528 0.04120858\n",
      " 0.00226359 0.0012557  0.00316    0.00026977 0.00117748 0.00056084\n",
      " 0.0002616  0.0007032  0.00428927 0.00195155 0.00113673]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([24, 21, 14, 23, 25, 12, 28, 22, 19,  4, 27,  7, 18, 20,  1,  0, 26,\n",
       "        6,  5,  8, 17,  2,  3, 10, 15, 11, 16,  9, 13])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = model_rf.feature_importances_\n",
    "indices_sorted = np.argsort(importances)\n",
    "print(importances)\n",
    "indices_sorted #importances 값이 작은 것부터 정렬함. 12번째의 importance가 가장 작다는 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "executionInfo": {
     "elapsed": 829,
     "status": "ok",
     "timestamp": 1668781894853,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "r0NKu0ZoXStz",
    "outputId": "730f9f36-25b9-485b-85ce-3836f3c65171"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12,10))\n",
    "plt.bar(range(len(importances)), importances[indices_sorted])\n",
    "plt.xticks(range(len(importances)), X.columns[indices_sorted], rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7J1na_u8XzOb"
   },
   "source": [
    "* Random Forest를 이용한 feature importance가 상위 4개인 것만 이용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EV3ux7PrX7op"
   },
   "outputs": [],
   "source": [
    "usecol = X.columns[indices_sorted[-4:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwHk6Bu4YMMW"
   },
   "outputs": [],
   "source": [
    "# Early stopping 적용을 위한 validation set 다시 만들기\n",
    "X_train_scaled, X_val_scaled, y_train, y_val = train_test_split(X_train_scaled, y_train, test_size = .2, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 148606,
     "status": "ok",
     "timestamp": 1668782152860,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "WuzqIfJ3aUK2",
    "outputId": "1f398d2c-a6ac-4a05-8bbd-627028059323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "418/418 [==============================] - 3s 6ms/step - loss: 0.0597 - accuracy: 0.9822 - val_loss: 0.0113 - val_accuracy: 0.9983\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0143 - accuracy: 0.9983 - val_loss: 0.0095 - val_accuracy: 0.9983\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0120 - accuracy: 0.9983 - val_loss: 0.0083 - val_accuracy: 0.9983\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0102 - accuracy: 0.9983 - val_loss: 0.0066 - val_accuracy: 0.9983\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 2s 6ms/step - loss: 0.0082 - accuracy: 0.9983 - val_loss: 0.0051 - val_accuracy: 0.9983\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 4s 9ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.0056 - val_accuracy: 0.9983\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0047 - val_accuracy: 0.9983\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0051 - val_accuracy: 0.9983\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0043 - val_accuracy: 0.9983\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0047 - val_accuracy: 0.9983\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0044 - val_accuracy: 0.9983\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0043 - val_accuracy: 0.9983\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.0047 - val_accuracy: 0.9983\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0042 - val_accuracy: 0.9983\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 0.0045 - val_accuracy: 0.9993\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.0047 - val_accuracy: 0.9993\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.0045 - val_accuracy: 0.9993\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.0046 - val_accuracy: 0.9993\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.0044 - val_accuracy: 0.9993\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0053 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 0.0047 - val_accuracy: 0.9993\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 0.0044 - val_accuracy: 0.9993\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0054 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 0.0046 - val_accuracy: 0.9993\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 0.0045 - val_accuracy: 0.9993\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.0045 - val_accuracy: 0.9993\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 0.0044 - val_accuracy: 0.9993\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 0.0049 - accuracy: 0.9993 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 3s 6ms/step - loss: 0.0049 - accuracy: 0.9993 - val_loss: 0.0044 - val_accuracy: 0.9993\n",
      "Epoch 44: early stopping\n",
      "2226/2226 [==============================] - 3s 1ms/step\n",
      "accuracy score : 0.9996\n",
      "precision score : 0.9027\n",
      "recall score : 0.8430\n",
      "f1 score : 0.8718\n"
     ]
    }
   ],
   "source": [
    "# Hidden layer의 개수를 5개, Dropout과 Earlystopping 기법 적용\n",
    "model = Sequential()\n",
    "model.add(Dense(30, activation = 'relu', input_dim = len(usecol)))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 5)\n",
    "history = model.fit(X_train_scaled[usecol], y_train, validation_data = (X_val_scaled[usecol], y_val), epochs = 50, batch_size = 512, callbacks = [es])\n",
    "\n",
    "y_prediction_ANN = model.predict(X_test_scaled[usecol])\n",
    "y_prediction_ANN = np.where(y_prediction_ANN.reshape(-1) > 0.5, 1., 0.)\n",
    "print_score(y_true = y_test, y_pred = y_prediction_ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 173825,
     "status": "ok",
     "timestamp": 1668783331980,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "9ZIDYXL7LMht",
    "outputId": "9dfb65f1-a3d3-4b86-fb38-161e9df269d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10681/10681 [==============================] - 33s 3ms/step - loss: 0.0286 - accuracy: 0.9979 - val_loss: 0.0097 - val_accuracy: 0.9985\n",
      "Epoch 2/5\n",
      "10681/10681 [==============================] - 36s 3ms/step - loss: 0.0137 - accuracy: 0.9982 - val_loss: 0.0086 - val_accuracy: 0.9985\n",
      "Epoch 3/5\n",
      "10681/10681 [==============================] - 34s 3ms/step - loss: 0.0116 - accuracy: 0.9982 - val_loss: 0.0070 - val_accuracy: 0.9985\n",
      "Epoch 4/5\n",
      "10681/10681 [==============================] - 33s 3ms/step - loss: 0.0101 - accuracy: 0.9982 - val_loss: 0.0052 - val_accuracy: 0.9985\n",
      "Epoch 5/5\n",
      "10681/10681 [==============================] - 34s 3ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.0055 - val_accuracy: 0.9985\n",
      "2226/2226 [==============================] - 3s 1ms/step\n",
      "accuracy score : 0.9983\n",
      "precision score : 0.0000\n",
      "recall score : 0.0000\n",
      "f1 score : 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Batch size 줄이고 learning rate 낮춰봄..\n",
    "# 적은 데이터로 조금씩 학습하며, 학습수 많아짐\n",
    "X_train_scaled, X_val_scaled, y_train, y_val = train_test_split(X_train_scaled, y_train, test_size = .2, random_state = 45)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, activation = 'relu', input_dim = len(usecol)))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(X_train_scaled[usecol], y_train, validation_data = (X_val_scaled[usecol], y_val), epochs = 5, batch_size = 16, callbacks = [es])\n",
    "\n",
    "y_prediction_ANN = model.predict(X_test_scaled[usecol])\n",
    "y_prediction_ANN = np.where(y_prediction_ANN.reshape(-1) > 0.5, 1., 0.)\n",
    "print_score(y_true = y_test, y_pred = y_prediction_ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 87747,
     "status": "ok",
     "timestamp": 1668784099304,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "O2P1L07hOMAL",
    "outputId": "ef0aa116-8462-49c1-a17c-6d1ed84256c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "668/668 [==============================] - 4s 4ms/step - loss: 0.0403 - accuracy: 0.9939 - val_loss: 0.0103 - val_accuracy: 0.9985\n",
      "Epoch 2/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0128 - accuracy: 0.9982 - val_loss: 0.0070 - val_accuracy: 0.9985\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.0045 - val_accuracy: 0.9985\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.0045 - val_accuracy: 0.9985\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9985\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.0041 - val_accuracy: 0.9985\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.0037 - val_accuracy: 0.9985\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0033 - val_accuracy: 0.9985\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.0035 - val_accuracy: 0.9985\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0039 - val_accuracy: 0.9985\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0042 - val_accuracy: 0.9985\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "Epoch 14/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.0040 - val_accuracy: 0.9985\n",
      "Epoch 15/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.0032 - val_accuracy: 0.9985\n",
      "Epoch 16/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "Epoch 17/30\n",
      "668/668 [==============================] - 3s 5ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.0035 - val_accuracy: 0.9992\n",
      "Epoch 18/30\n",
      "668/668 [==============================] - 3s 5ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.0032 - val_accuracy: 0.9995\n",
      "Epoch 19/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0036 - val_accuracy: 0.9995\n",
      "Epoch 20/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0031 - val_accuracy: 0.9995\n",
      "Epoch 21/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.0034 - val_accuracy: 0.9990\n",
      "Epoch 22/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.0031 - val_accuracy: 0.9995\n",
      "Epoch 23/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.0030 - val_accuracy: 0.9993\n",
      "Epoch 24/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.0031 - val_accuracy: 0.9993\n",
      "Epoch 25/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.0031 - val_accuracy: 0.9994\n",
      "Epoch 26/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.0031 - val_accuracy: 0.9995\n",
      "Epoch 27/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.0033 - val_accuracy: 0.9995\n",
      "Epoch 28/30\n",
      "668/668 [==============================] - 5s 7ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
      "Epoch 28: early stopping\n",
      "2226/2226 [==============================] - 4s 2ms/step\n",
      "accuracy score : 0.9995\n",
      "precision score : 0.9135\n",
      "recall score : 0.7851\n",
      "f1 score : 0.8444\n"
     ]
    }
   ],
   "source": [
    "# Batch size 많이, learning rate 높게\n",
    "model = Sequential()\n",
    "model.add(Dense(30, activation = 'relu', input_dim = len(usecol)))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 5)\n",
    "history = model.fit(X_train_scaled[usecol], y_train, validation_data = (X_val_scaled[usecol], y_val), epochs = 30, batch_size = 256, callbacks = [es])\n",
    "\n",
    "y_prediction_ANN = model.predict(X_test_scaled[usecol])\n",
    "y_prediction_ANN = np.where(y_prediction_ANN.reshape(-1) > 0.5, 1., 0.)\n",
    "print_score(y_true = y_test, y_pred = y_prediction_ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46944,
     "status": "ok",
     "timestamp": 1668784861061,
     "user": {
      "displayName": "Myeonghun Lee",
      "userId": "07363699607077136340"
     },
     "user_tz": -540
    },
    "id": "iQCu31s-Tngf",
    "outputId": "2176ec3b-508a-466f-d2b7-534d0c18acd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "668/668 [==============================] - 6s 6ms/step - loss: 0.0435 - accuracy: 0.9917 - val_loss: 0.0094 - val_accuracy: 0.9985\n",
      "Epoch 2/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0160 - accuracy: 0.9982 - val_loss: 0.0075 - val_accuracy: 0.9985\n",
      "Epoch 3/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0124 - accuracy: 0.9982 - val_loss: 0.0050 - val_accuracy: 0.9985\n",
      "Epoch 4/30\n",
      "668/668 [==============================] - 3s 5ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.0047 - val_accuracy: 0.9985\n",
      "Epoch 5/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.0039 - val_accuracy: 0.9985\n",
      "Epoch 6/30\n",
      "668/668 [==============================] - 3s 5ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.0035 - val_accuracy: 0.9985\n",
      "Epoch 7/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0079 - accuracy: 0.9982 - val_loss: 0.0039 - val_accuracy: 0.9985\n",
      "Epoch 8/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.0033 - val_accuracy: 0.9985\n",
      "Epoch 9/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.0033 - val_accuracy: 0.9985\n",
      "Epoch 10/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0035 - val_accuracy: 0.9995\n",
      "Epoch 11/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0072 - accuracy: 0.9989 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 12/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0072 - accuracy: 0.9990 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "Epoch 13/30\n",
      "668/668 [==============================] - 3s 4ms/step - loss: 0.0075 - accuracy: 0.9991 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "Epoch 13: early stopping\n",
      "2226/2226 [==============================] - 3s 1ms/step\n",
      "accuracy score : 0.9995\n",
      "precision score : 0.9126\n",
      "recall score : 0.7769\n",
      "f1 score : 0.8393\n"
     ]
    }
   ],
   "source": [
    "class_weight = {0. : 1, 1. : 1.25}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, activation = 'relu', input_dim = len(usecol)))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dropout(.3))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 5)\n",
    "history = model.fit(X_train_scaled[usecol], y_train, validation_data = (X_val_scaled[usecol], y_val), epochs = 30, batch_size = 256, callbacks = [es], class_weight = class_weight)\n",
    "\n",
    "y_prediction_ANN = model.predict(X_test_scaled[usecol])\n",
    "y_prediction_ANN = np.where(y_prediction_ANN.reshape(-1) > 0.5, 1., 0.)\n",
    "print_score(y_true = y_test, y_pred = y_prediction_ANN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wjxPcVwdMqm"
   },
   "source": [
    "* 중요도 상위 5개 feature 대신 모든 feature를 이용해 학습했을 때, score가 크게 증가하지 않았음\n",
    "\n",
    "\n",
    "* variable selection을 해도 성능차이가 없으며, 연산량은 크게 감소함을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3aZZXbHddO7"
   },
   "source": [
    "## Question\n",
    "\n",
    "* 왜 Tensorflow로 돌린 logistic은 이상한 결과가 나왔는가?\n",
    "\n",
    "* Epoch수, Batch size, Learning rate, Hidden layer의 수, Neuron의 수 등 결정하는 방법?\n",
    "\n",
    "* Dropout과 Early stopping의 효과가 미미했는데 이유?\n",
    "\n",
    "* 학습시 class_weight을 적용해봤는데, 딥러닝에서 imbalance data를 학습할 때 이와 같이 하는게 일반적인지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2gVzj_AF20q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNlFmfxc/RrtwamZb0Vds5a",
   "collapsed_sections": [
    "Fm8g6CQTNrEc"
   ],
   "mount_file_id": "1q3qc3kPJtYA0WaCdIbLVPUyj996W74Of",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
